
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../../diffusion/">
      
      
        <link rel="next" href="../../tokens/cosmos_tokenizer/cosmos_tokenizer/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.16">
    
    
      
        <title>Autoregressive models - World Foundation Models</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.7e37652d.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#modelos-autorregressivos-e-aplicacao-em-world-foundation-models-wfms" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="World Foundation Models" class="md-header__button md-logo" aria-label="World Foundation Models" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            World Foundation Models
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Autoregressive models
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="World Foundation Models" class="md-nav__button md-logo" aria-label="World Foundation Models" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    World Foundation Models
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../diffusion/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Diffusion models
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Autoregressive models
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Autoregressive models
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#o-que-e-um-modelo-autorregressivo" class="md-nav__link">
    <span class="md-ellipsis">
      O que é um Modelo Autorregressivo?
    </span>
  </a>
  
    <nav class="md-nav" aria-label="O que é um Modelo Autorregressivo?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#exemplos-de-uso" class="md-nav__link">
    <span class="md-ellipsis">
      Exemplos de uso
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#wfm-baseado-em-modelo-autoregressivo" class="md-nav__link">
    <span class="md-ellipsis">
      WFM baseado em modelo autoregressivo
    </span>
  </a>
  
    <nav class="md-nav" aria-label="WFM baseado em modelo autoregressivo">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#arquitetura-do-sistema" class="md-nav__link">
    <span class="md-ellipsis">
      Arquitetura do Sistema
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vantagens-da-abordagem" class="md-nav__link">
    <span class="md-ellipsis">
      Vantagens da Abordagem
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#limitacoes" class="md-nav__link">
    <span class="md-ellipsis">
      Limitações
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Tokens
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Tokens
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1" >
        
          
          <label class="md-nav__link" for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Cosmos Tokenizer
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1">
            <span class="md-nav__icon md-icon"></span>
            Cosmos Tokenizer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokens/cosmos_tokenizer/cosmos_tokenizer/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Cosmos Tokenizer
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokens/cosmos_tokenizer/wavelet_compression/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Decomposição de imagem com Wavelets
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokens/dsc_tokenization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    DSC Tokenization
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#o-que-e-um-modelo-autorregressivo" class="md-nav__link">
    <span class="md-ellipsis">
      O que é um Modelo Autorregressivo?
    </span>
  </a>
  
    <nav class="md-nav" aria-label="O que é um Modelo Autorregressivo?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#exemplos-de-uso" class="md-nav__link">
    <span class="md-ellipsis">
      Exemplos de uso
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#wfm-baseado-em-modelo-autoregressivo" class="md-nav__link">
    <span class="md-ellipsis">
      WFM baseado em modelo autoregressivo
    </span>
  </a>
  
    <nav class="md-nav" aria-label="WFM baseado em modelo autoregressivo">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#arquitetura-do-sistema" class="md-nav__link">
    <span class="md-ellipsis">
      Arquitetura do Sistema
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vantagens-da-abordagem" class="md-nav__link">
    <span class="md-ellipsis">
      Vantagens da Abordagem
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#limitacoes" class="md-nav__link">
    <span class="md-ellipsis">
      Limitações
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="modelos-autorregressivos-e-aplicacao-em-world-foundation-models-wfms">Modelos Autorregressivos e Aplicação em World Foundation Models (WFMs)</h1>
<h2 id="o-que-e-um-modelo-autorregressivo">O que é um Modelo Autorregressivo?</h2>
<p>Um modelo autorregressivo (AR) é um tipo de modelo estatístico que prevê valores futuros em uma sequência com base em seus próprios valores passados. O termo "autorregressivo" reflete a ideia de que o modelo "faz regressão sobre si mesmo", ou seja, as previsões são feitas a partir das observações anteriores. Nele, temos a relação:</p>
<ul>
<li>
<p><strong>Entrada</strong>: Observações passadas (ex: palavras anteriores em uma frase, quadros em um vídeo).</p>
</li>
<li>
<p><strong>Saída</strong>: Previsão do próximo valor na sequência (ex: próxima palavra, próximo quadro).</p>
</li>
</ul>
<p>A fórmula que descreve os modelos autoregressivos é expressa como</p>
<div class="arithmatex">\[X_t = \sum_{i=1}^{p} \phi_i X_{t-i} + \varepsilon_t\]</div>
<p>Onde:</p>
<ul>
<li><span class="arithmatex">\(X_t\)</span> é o valor da série temporal no tempo <span class="arithmatex">\(t\)</span>,</li>
<li><span class="arithmatex">\(\phi_i\)</span> são os coeficientes autoregressivos,</li>
<li><span class="arithmatex">\(p\)</span> é a ordem do modelo autoregressivo,</li>
<li><span class="arithmatex">\(X_{t-i}\)</span> são os valores passados da série temporal</li>
<li><span class="arithmatex">\(\varepsilon_t\)</span> é o erro ou ruído, considerado como uma variável aleatória com média zero e variância constante</li>
</ul>
<p><img alt="Comparação de 2 modelos AR" src="../src/AR_comparison.png" /></p>
<blockquote>
<p>Comparação entre 2 modelos autoregressivos com parâmetros diferentes. A imagem mostra a flexibilidade dos modelos em tratar diferentes padrões de séries temporais.</p>
</blockquote>
<h3 id="exemplos-de-uso">Exemplos de uso</h3>
<p>Modelos autoregressivos são muito usados em áreas como processamento de linguagem natural (PLN) e séries temporais, devido à sua capacidade de capturar dependências sequenciais e temporais. Alguns exemplos de modelos autoregressivos são:</p>
<ul>
<li>
<p><strong>Séries temporais</strong>: usados para prever dados sequenciais, como preços de ações, previsão do tempo ou tráfego de dados</p>
</li>
<li>
<p><strong>PLN</strong>: modelos como o GPT funcionam com abordagem autoregressiva, gerando a próxima palavra com base nas palavras anteriores, sequencialmente. A dependência entre palavras anteriores é importante para a geração de contexto e de frases coerentes.</p>
</li>
<li>
<p><strong>Áudio e Sinais</strong>: O modelo AR é uma base clássica na análise de sinais de áudio, como na codificação de áudio, reconhecimento de fala e processamento de sinais de música. A autocorrelação entre os dados de áudio em diferentes tempos pode ser modelada para prever sons ou identificar padrões temporais.</p>
</li>
</ul>
<p><img alt="Exemplo de autoregressão aplicado em contexto de PLN" src="../src/exemplo_autoregressao_linguagem.png" /></p>
<blockquote>
<p>Exemplo de aplicação autoregressiva para previsão da próxima palavra em um contexto. Percebe-se a sequencialidade das previsões, em que apenas uma palavra é predita de cada vez. Além disso, cada palavra depende das palavras previamente geradas, demonstrando o caráter autoregressivo dos modelos de linguagem.</p>
</blockquote>
<h2 id="wfm-baseado-em-modelo-autoregressivo">WFM baseado em modelo autoregressivo</h2>
<p>WFMs que utilizam abordagens autoregressivas aplicam os mesmos princípios dos modelos de linguagem à geração de ambientes simulados.
Nesta arquitetura, a simulação de mundo é gerada por meio da previsão do próximo token, onde cada frame de vídeo é convertido em uma sequência de tokens que são processados sequencialmente pelo modelo. O caráter autoregressivo vem justamente da previsão dos próximos tokens com base na sequência de frames já vista.</p>
<p>Esses tokens podem representar pixels, patches visuais (como no Vision Transformer), embeddings de texto, comandos ou ações. O modelo é treinado para prever o próximo token a partir de um contexto acumulado, respeitando a ordem causal dos dados: cada predição é condicionada apenas pelos valores presentes e passados de entrada, mas nunca de valores futuros.</p>
<p><img alt="Entradas para o WFM" src="../src/WFM_input_imagens_texto.png" /></p>
<blockquote>
<p>Frequentemente usa-se a combinação de imagens e texto para gerar as ações que a IA física realizará. A combinação de frames de imagens com inputs textuais, proporcionados pela arquitetura transformer do modelo, permite um controle mais fino das ações realizadas pelo agente no mundo real.</p>
</blockquote>
<p>Essa integração multimodal (combinação de várias modalidades de dados), permite que o modelo funcione como um agente geral que observa o ambiente (por vídeo ou imagens), entende comandos (por texto) e gera sequências de ações com base nessas entradas. O modelo aprende a simular e antecipar estados do mundo, funcionando como um planejador autoregressivo que age com base em observações contínuas do ambiente.</p>
<h3 id="arquitetura-do-sistema">Arquitetura do Sistema</h3>
<p><img alt="alt text" src="../src/architecture.png" /></p>
<p>A arquitetura das WFMs autoregressivas segue três componentes principais:</p>
<ol>
<li>
<p><strong>Tokenização de Vídeo</strong>:</p>
<ul>
<li>Os vídeos são inicialmente passados por um tokenizador visual, que transforma cada frame em uma sequência de tokens discretos. Esses tokens são representações compactas dos frames. Nessa arquitetura ele gera um tensor de (8x16x16).</li>
</ul>
</li>
<li>
<p><strong>Núcleo Autoregressivo</strong>:</p>
<ul>
<li>
<p>O núcleo do modelo é um Transformer decoder, treinado para prever o próximo token com base na sequência anterior (aqui está o caráter autoregressivo). Para lidar com a estrutura tridimensional dos vídeos (tempo, altura e largura), são utilizados embeddings posicionais espaciais e temporais. Ele também pode receber informações adicionais, como instruções em linguagem natural, por meio de mecanismos de atenção cruzada.</p>
</li>
<li>
<p><strong>Positional Embedding:</strong> Modelos baseados em atenção (Transformers) não entendem ordem ou posição por padrão. Para que o modelo processe vídeos (ou qualquer dado sequencial), é essencial dizer onde e quando cada token ocorre. É aqui que entram os positional embeddings, e neste caso, temos dois tipos combinados:</p>
<ul>
<li>
<p><strong>Absolute Positional Embedding:</strong> Para cada posição no vídeo, o modelo atribui um vetor fixo. Em seguida esse vetor é somado diretamente ao embedding do token de vocabulário:</p>
</li>
<li>
<div class="arithmatex">\[embedding\_vocabulário + embedding\_posicional = embedding\_final\]</div>
</li>
<li>
<p><strong>3D Rope:</strong> RoPE (Rotary Positional Embedding) é um tipo de embedding que incorpora posição no vetor via rotação trigonométrica, ao invés de somar um vetor fixo. Ao aplicar a rotação trigonométrica no vetor 3D ele é consegue inferir, dimensões relativas entre tokens, direções de movimento, ritmos e padrões espacias e temporais.</p>
</li>
</ul>
</li>
<li>
<p><strong>T5 text encoder:</strong> O T5 Text Encoder é a parte codificadora do modelo T5 (Text-to-Text Transfer Transformer), projetado para transformar qualquer tarefa de linguagem natural em uma tarefa de texto para texto.
Nesse encoder, o texto de entrada (como um prompt descritivo) é tokenizado e processado por uma pilha de camadas Transformer, gerando uma sequência de vetores contextuais densos que capturam o significado semântico de cada palavra no contexto da frase. 
Esses embeddings são então usados na cross-attention com os tokens do vídeo, permitindo que o modelo condicione a reconstrução ou geração de vídeo com base no conteúdo textual. O uso do T5 encoder permite que o sistema compreenda comandos em linguagem natural com profundidade semântica, guiando o processamento multimodal de forma flexível e expressiva.</p>
</li>
<li>
<p><strong>Cross Attention:</strong> A cross-attention permite que os tokens do vídeo sejam guiados pelos tokens do texto, combinando as duas modalidades de forma inteligente para interpretar ou gerar vídeo com base em linguagem natural.
  A equação usada tanto no <strong>self-attention</strong> quanto no <strong>cross-attention</strong> é:</p>
</li>
<li>
<div class="arithmatex">\[\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right) V\]</div>
</li>
<li>
<p>Onde:</p>
<ul>
<li><span class="arithmatex">\(Q\)</span> = matriz de <strong>queries</strong></li>
<li><span class="arithmatex">\(K\)</span> = matriz de <strong>keys</strong></li>
<li><span class="arithmatex">\(V\)</span> = matriz de <strong>values</strong></li>
<li><span class="arithmatex">\(d_k\)</span> = dimensão dos vetores de chave (normalizador de escala)</li>
<li><span class="arithmatex">\(QK^T\)</span> = produto escalar entre queries e keys</li>
<li><span class="arithmatex">\(\text{softmax}\)</span> = transforma os pesos em probabilidades</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Decodificação</strong>:</p>
<ul>
<li>A geração acontece de forma sequencial, token por token, até que um novo frame seja reconstruído. Há a possibilidade dos tokens gerados serem passados por um decoder de difusão para melhorar a qualidade visual</li>
</ul>
</li>
</ol>
<h3 id="vantagens-da-abordagem">Vantagens da Abordagem</h3>
<p>Entre os principais pontos positivos dessa arquitetura está sua <strong>escalabilidade</strong>: por herdar a estrutura dos grandes modelos de linguagem (LLMs), ela se adapta bem ao uso de grandes volumes de dados. 
Outro aspecto importante é a <strong>flexibilidade</strong>: o modelo pode lidar com diferentes tipos de entrada (texto, vídeo, imagem), gerar sequências de comprimentos variados e ser controlado de maneira precisa por prompts</p>
<h3 id="limitacoes">Limitações</h3>
<p>Apesar das vantagens, há desafios inerentes à abordagem. A <strong>geração sequencial</strong> faz com que o processo seja naturalmente mais lento e custoso do ponto de vista computacional, principalmente em vídeos longos. 
Além disso, como cada passo depende do anterior, <strong>pequenos erros tendem a se propagar</strong> e se amplificar ao longo da sequência, o que pode comprometer a coerência do vídeo gerado. 
Por fim, o processo de tokenização agressiva, necessário para reduzir o custo computacional, pode introduzir <strong>objetos inesperados</strong> que afetam a fidelidade da simulação, motivo pelo qual, muitas vezes, é necessário aplicar um pós-processamento com modelos de difusão.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.50899def.min.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>