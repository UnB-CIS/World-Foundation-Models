{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementação do Encoder e Decoder Determinístico de Ação\n",
        "\n",
        "\n",
        "Seguindo o modelo conceitual definido pela arquitetura, em que o World Model opera com pares instantâneos `(St​,at​)`, este notebook irá construir e testar a arquitetura básica de codificação de uma única ação em um instante de tempo `t`. O modelo do enconder traduz o objeto JSON que representa a ação da simulação em um vetor latente compacto `za` e o decoder o reconstrói, a fim de testar a corretude do encoder.\n",
        "\n",
        "Cada ação tem:\n",
        "- `time`: timestamp em segundos\n",
        "- `type`: tipo de ação (mouse_down)\n",
        "- `object`: objeto afetado (ball)\n",
        "- `pos`: [x, y] coordenadas da ação\n",
        "\n",
        "Note que o encoder não codifica o campo `time`, assume-se que a ação e o frame estarão casados temporalmente na etapa do WFM"
      ],
      "metadata": {
        "id": "hxYwMDg5G7Oz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Dependências"
      ],
      "metadata": {
        "id": "ZIdMiQqrG_H6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Sdx_icDB2Vdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f90b044-33e0-4700-94ee-dcf22aecf545"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x79339d090d30>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "# Importações necessárias\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import json\n",
        "import random\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Garante a reprodutibilidade\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Definições do Cenário e Codificação\n",
        "\n",
        "A primeira etapa consiste em codificar uma ação em um tensor do Pytorch. A ausência de ação corresponde à um tensor nulo."
      ],
      "metadata": {
        "id": "cdpGn7BkHDxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensões da tela do cenário 1\n",
        "SCREEN_WIDTH = 800\n",
        "SCREEN_HEIGHT = 600\n",
        "\n",
        "# Codificação One-Hot\n",
        "TYPE_ENCODING = {\n",
        "    'mouse_down': [1.0],  # Ação presente\n",
        "    'none':  [0.0]        # Ação ausente\n",
        "}\n",
        "\n",
        "OBJECT_ENCODING = {\n",
        "    'ball': [1.0], # Cenário 1 só tem bolas\n",
        "    'none': [0.0]  # Falta de ação, 0 para que o vetor final da falta de ação seja nulo\n",
        "}\n",
        "\n",
        "# Dimensão do vetor de entrada: [type(1)] + [object(1)] + [x_norm(1)] + [y_norm(1)]\n",
        "INPUT_VECTOR_DIM = 4\n",
        "\n",
        "LATENT_ACTION_DIM = 16 # Za: Dimensão do Espaço Latente da Ação"
      ],
      "metadata": {
        "id": "8GiQ-3UBIFqz"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função de codificação\n",
        "def encoding_function(action_data: dict = None) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "    Converte um dicionário de ação ou um sinal de 'ausência de ação' em um tensor\n",
        "\n",
        "    Args:\n",
        "        action_data: Dicionário de ação (JSON) ou None na ausência dela\n",
        "\n",
        "    Returns:\n",
        "        Um tensor PyTorch de dimensão [INPUT_VECTOR_DIM]\n",
        "  \"\"\"\n",
        "\n",
        "  # Caso de ausencia de ação\n",
        "  if action_data is None:\n",
        "    type_vector = TYPE_ENCODING['none']\n",
        "    object_vector = OBJECT_ENCODING['none']\n",
        "    x_norm = 0.0\n",
        "    y_norm = 0.0\n",
        "\n",
        "  # Ação positiva (mouse_down)\n",
        "  elif action_data:\n",
        "    type_vector = TYPE_ENCODING['mouse_down']\n",
        "    object_vector = OBJECT_ENCODING.get(action_data['object'], [0.0]) # Pega o vetor da ball\n",
        "    pos_x = action_data['pos'][0]\n",
        "    pos_y = action_data['pos'][1]\n",
        "\n",
        "    # Normaliza as coordenadas da tela para o intervalo [0, 1]\n",
        "    x_norm = pos_x / SCREEN_WIDTH\n",
        "    y_norm = pos_y / SCREEN_HEIGHT\n",
        "\n",
        "  input_list = type_vector + object_vector + [x_norm, y_norm]\n",
        "\n",
        "  if len(input_list) != INPUT_VECTOR_DIM:\n",
        "    raise ValueError(f\"Dimensão do vetor inválida: {len(input_list)}\")\n",
        "\n",
        "  return torch.tensor(input_list, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "WyiQULmkJKEz"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de ação mouse_down\n",
        "exemplo_acao = {\n",
        "    \"time\": 9.40,\n",
        "    \"type\": \"mouse_down\",\n",
        "    \"object\": \"ball\",\n",
        "    \"pos\": [400, 300]\n",
        "}\n",
        "\n",
        "# Testando codificação de ação presente\n",
        "vetor_acao = encoding_function(exemplo_acao)\n",
        "print(\"Ação presente (mouse_down):\", vetor_acao.tolist())\n",
        "\n",
        "# Testando codificação de ausência de ação (No-Op)\n",
        "vetor_none = encoding_function(None)\n",
        "print(\"Ausência de ação:\", vetor_none.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTmDJytpTMzP",
        "outputId": "6c4597da-8721-48d2-aa90-5afda4ff5b02"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ação presente (mouse_down): [1.0, 1.0, 0.5, 0.5]\n",
            "Ausência de ação: [0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Criando o Encoder e Decoder\n",
        "\n",
        "Agora vamos criar uma rede neural simples que transforma esses 4 features em um embedding mais rico. Depois, vamos fazer o mesmo só que para o movimento contrário. Optou-se por uma rede simples inicialmente, para fins de teste."
      ],
      "metadata": {
        "id": "dUEH1ACJV0Rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextEncoder(nn.Module):\n",
        "  \"\"\"\n",
        "  Encoder determinístico (embedding)\n",
        "  Mapeia o vetor de entrada para o espaço latente de 16 dimensões\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, input_dim=INPUT_VECTOR_DIM, latent_dim=LATENT_ACTION_DIM):\n",
        "    super().__init__()\n",
        "\n",
        "    self.latent_dim = latent_dim\n",
        "\n",
        "    self.net = nn.Sequential(\n",
        "      nn.Linear(input_dim, 16),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(16, latent_dim)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "skhXNuOlP1uw"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDecoder(nn.Module):\n",
        "  \"\"\"\n",
        "  Decoder determinístico (reconstrução)\n",
        "  Mapeia o vetor latente de volta para o espaço da ação original\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, latent_dim=LATENT_ACTION_DIM, output_dim=INPUT_VECTOR_DIM):\n",
        "    super().__init__()\n",
        "\n",
        "    self.net = nn.Sequential(\n",
        "      nn.Linear(latent_dim, 16),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(16, output_dim)\n",
        "    )\n",
        "\n",
        "  def forward(self, z):\n",
        "    x = self.net(z)\n",
        "    return torch.sigmoid(x)\n",
        "\n",
        "\n",
        "class TextDecoder(nn.Module):\n",
        "  \"\"\"\n",
        "  Decoder determinístico (reconstrução)\n",
        "  Mapeia o vetor latente de volta para o espaço da ação original\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, latent_dim=LATENT_ACTION_DIM, output_dim=INPUT_VECTOR_DIM):\n",
        "    super().__init__()\n",
        "\n",
        "    self.net = nn.Sequential(\n",
        "      nn.Linear(latent_dim, 32),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(32, 16),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(16, output_dim)\n",
        "    )\n",
        "\n",
        "  def forward(self, z):\n",
        "    return self.net(z)\n"
      ],
      "metadata": {
        "id": "tio4iMccYTiB"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Geração de um dataset sintético simples\n",
        "\n",
        "Como a estrutura das ações é muito simples, é mais vantajoso montar um dataset sintético com mais ações do que usar o dataset real com as 200 simulações. Note que na simulação real, menos de 1% dos frames terão uma ação correspondente. Mesmo assim, opta-se por fazer um split de 50/50 em dados com ação positiva e nula. Isso se deve principalmente porque caso a divisão que espelha o comportamento real fosse usada, o modelo não teria incentivos para minimizar a perda das ações com clique, e focaria apenas em minimizar ao máximo o erro da ausência de ação, ignorando o outro caso."
      ],
      "metadata": {
        "id": "qBlYqqB9cBYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_SAMPLES = 2000\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "synthetic_inputs = []\n",
        "\n",
        "# Gerar amostras de clique\n",
        "for _ in range(1000): # 50% de 2000\n",
        "\n",
        "  pos_x = random.randint(50, 750)\n",
        "  pos_y = random.randint(50, 500)\n",
        "\n",
        "  # Monta a estrutura de dados\n",
        "  action_data = {\n",
        "    \"type\": \"mouse_down\",\n",
        "    \"object\": \"ball\",\n",
        "    \"pos\": [pos_x, pos_y]\n",
        "  }\n",
        "\n",
        "  # Codifica e armazena\n",
        "  synthetic_inputs.append(encoding_function(action_data))\n",
        "\n",
        "\n",
        "# Gerar amostras de Ausência de Ação\n",
        "for _ in range(1000): # 50% de 2000\n",
        "  # Quando não tem ação, passa um None à função de encoding\n",
        "  synthetic_inputs.append(encoding_function(None))"
      ],
      "metadata": {
        "id": "ORoCvrBVceZp"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_tensor = torch.stack(synthetic_inputs)\n",
        "\n",
        "# Note que como queremos reconstruir a entrada, ela é a mesma coisa que a saída\n",
        "dataset = TensorDataset(full_tensor, full_tensor)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "print(f\"Dataset Sintético Gerado: {len(full_tensor)} amostras.\")\n",
        "print(f\"Shape de um Batch: {next(iter(dataloader))[0].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r3PyF72R1LK",
        "outputId": "cc42ad78-3769-48d7-ca5f-58babd794bf9"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Sintético Gerado: 2000 amostras.\n",
            "Shape de um Batch: torch.Size([64, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Treinamento"
      ],
      "metadata": {
        "id": "U1CNwmw9eGeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iniciação dos modelos e otimizador\n",
        "text_encoder = TextEncoder()\n",
        "text_decoder = TextDecoder()\n",
        "\n",
        "# Vamos combinar os parâmetros dos dois modelos em uma única lista de parâmetros e otimizá-los de uma vez\n",
        "params = list(text_encoder.parameters()) + list(text_decoder.parameters())\n",
        "optimizer = optim.Adam(params, lr=1e-3)\n",
        "\n",
        "# Função de Perda é a MSE\n",
        "loss_function = nn.MSELoss()"
      ],
      "metadata": {
        "id": "j2N-9JrVTVBm"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 20\n",
        "print(\"Iniciando treinamento\")\n",
        "\n",
        "train_losses = [] # Perdas de treinamento para plotar depois\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    total_loss = 0  # Acumula a perda total de cada época\n",
        "\n",
        "    # Loop dos batches\n",
        "    for data, _ in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass, codifica na representação latente\n",
        "        z_a = text_encoder(data)\n",
        "\n",
        "        # Forward pass, decodifica a representação latente\n",
        "        reconstruction = text_decoder(z_a)\n",
        "\n",
        "        # Calcula a perda entre a reconstrução e os dados originais\n",
        "        loss = loss_function(reconstruction, data)\n",
        "\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Atualiza os pesos do modelo com base nos gradientes\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    train_losses.append(avg_loss)\n",
        "\n",
        "    # Mostra a perda a cada 5 épocas\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Loss de Reconstrução: {avg_loss:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCrX5bDwUOau",
        "outputId": "f3af6d83-f596-458b-971a-a42a7bbfc762"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando treinamento\n",
            "Epoch [5/20], Loss de Reconstrução: 0.013939\n",
            "Epoch [10/20], Loss de Reconstrução: 0.010992\n",
            "Epoch [15/20], Loss de Reconstrução: 0.008542\n",
            "Epoch [20/20], Loss de Reconstrução: 0.003926\n"
          ]
        }
      ]
    }
  ]
}