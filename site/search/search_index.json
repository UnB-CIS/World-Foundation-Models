{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"tokens/tokens/","title":"Tokeniza\u00e7\u00e3o | Tokenization","text":"<ul> <li>Tokeniza\u00e7\u00e3o | Tokenization</li> <li>Summary of chapter 4 in Cosmos paper<ul> <li>Overview</li> </ul> </li> <li>Refer\u00eancias</li> </ul>"},{"location":"tokens/tokens/#summary-of-chapter-4-in-cosmos-paper","title":"Summary of chapter 4 in Cosmos paper","text":""},{"location":"tokens/tokens/#overview","title":"Overview","text":"<p>Tokenizers are fundamental building blocks of modern large-scale models. They transform raw data into more efficient representations by learning a bottle-necked latent space discovered in an unsupervised manner. Specifically, visual tokenizers map raw and redundant visual data into compact semantic tokens, making them crucial for handling high-dimensional visual data.</p> <p>The image bellow illustrates the tokenization training pipeline, where the goal is to train the encoder and decoder so that the bottleneck token representation maximally preserves visual information in the input.</p> <p></p> <p>In the pipeline, an input video is encoded into tokens, which are usually much more compact than the input video. The decoder then reconstructs the input video from the tokens. Tokenizer training is about learning the encoder and decoder to maximally preserve the visual information in the tokens.</p> <p>Tokenizers come in two types: continuous and discrete. Continuous tokenizers encode visual data into continuous latent embeddings, as in latent diffusion models like Stable Diffusion or VideoLDM. These embeddings are suitable for models that generate data by sampling from continuous distributions. Discrete tokenizers encode visual data into discrete latent codes, mapping them into quantized indices, as seen in autoregressive transformers such as VideoPoet. This discrete representation is necessary for models such as GPT that are trained with the cross-entropy loss.</p> <p>The success of tokenizers largely relies on their ability to deliver high compression rates without compromising their subsequent visual reconstruction quality. On one hand, high compression reduces storage and computational demands. On the other hand, excessive compression can lead to the loss of essential visual details. This trade-off presents a significant challenge in tokenizer design.</p> <p>The following image illustrates the two types of tokens:</p> <p>TODO aqui </p> <p>The following table illustrates different visual Tokenizers and their capabilities:</p> <p></p> <p>The Cosmos Tokenizer uses a lightweight and computationally efficient architecture with a temporally causal mechanism. Specifically, it employs causal temporal convolution layers and causal temporal attention layers to preserve the natural temporal order of video frames.</p> <p>The tokenizers are trained directly on high-resolution images and long-duration videos without limiting the categories or aspect ratios. The Cosmos Tokenizer operates across various aspect ratios. They are temporally length-agnostic during inference, capable of tokenizing beyond the temporal length on which it was trained.</p> <p>The plots bellow show the comparison in performance between the Cosmos Tokenizer and other ones, and denotes the superior quality even at higher compression rates:</p> <p></p>"},{"location":"tokens/tokens/#referencias","title":"Refer\u00eancias","text":"<p>Cosmos World Foundation Model Platform for Physical AI</p>"}]}